{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_toolkit import df_to_X_y\n",
    "from ml_toolkit import plot_predictions\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.losses import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_folder = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..', 'HeroysundBridge-ML'))\n",
    "asset_folder = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..', 'HeroysundBridge-ML-Assets'))\n",
    "\n",
    "print(\"Path to git folder:\", git_folder)\n",
    "print(\"Path to asset folder:\", asset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opening file: \\silver\\combined with relevant columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(os.path.join(asset_folder, 'silver','combined_data_v01.parquet'))\n",
    "df.index = pd.to_datetime(df['Date'], format='%Y%m%d%H')\n",
    "df.to_csv(os.path.join(asset_folder, 'silver','inspection.csv'))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding relevant time/dates columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset = df[['Point_1_N_mean', 'PT100_Temperature_mean', 'Average_Global_Radiation_(1h)']]\n",
    "model_dataset.loc[:, 'time_unit'] = pd.to_datetime(df['Date'], format='%Y%m%d%H')\n",
    "\n",
    "model_dataset['hour'] = model_dataset['time_unit'].dt.hour\n",
    "model_dataset['date'] = model_dataset['time_unit'].dt.dayofyear\n",
    "model_dataset['year'] = model_dataset['time_unit'].dt.year\n",
    "\n",
    "model_dataset.drop(columns=['time_unit'], inplace=True)  # Drop the temporary column if needed\n",
    "model_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(model_dataset)\n",
    "training_split = int(0.8*dataset_size)\n",
    "validation_split = int(0.15*dataset_size)\n",
    "test_split = int(0.05*dataset_size)\n",
    "window_size = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assigning labels and targets - x- and y- train,-val and -test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_to_X_y(model_dataset, window_size)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# Splitting the data into training, validation and test sets\n",
    "X_train, y_train = X[:training_split], y[:training_split]\n",
    "X_valid, y_valid = X[training_split:(training_split + validation_split)], y[training_split:(training_split + validation_split)]\n",
    "X_test, y_test = X[(training_split + validation_split):], y[(training_split + validation_split):]\n",
    "print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normlaization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to 2D (Normalisation requires 2D input)\n",
    "X_train_2D = np.reshape(X_train, (X_train.shape[0] * X_train.shape[1], X_train.shape[2]))\n",
    "X_valid_2D = np.reshape(X_valid, (X_valid.shape[0] * X_valid.shape[1], X_valid.shape[2]))\n",
    "X_test_2D = np.reshape(X_test, (X_test.shape[0] * X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "# Apply scaling\n",
    "scaler_x = StandardScaler()\n",
    "X_train_scaled_2D = scaler_x.fit_transform(X_train_2D)\n",
    "X_valid_scaled_2D = scaler_x.transform(X_valid_2D)\n",
    "X_test_scaled_2D = scaler_x.transform(X_test_2D)\n",
    "\n",
    "# Reshape back to 3D\n",
    "X_train_scaled = np.reshape(X_train_scaled_2D, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "X_valid_scaled = np.reshape(X_valid_scaled_2D, (X_valid.shape[0], X_valid.shape[1], X_valid.shape[2]))\n",
    "X_test_scaled = np.reshape(X_test_scaled_2D, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_valid_scaled = scaler_y.transform(y_valid.reshape(-1, 1))\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'conv_model_1'\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "learning_rate = 0.0001\n",
    "patience = 10\n",
    "verbose = 1\n",
    "saving_frequency = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((window_size, (len(model_dataset.columns)-1))))\n",
    "model.add(Conv1D(64, kernel_size=2, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = ModelCheckpoint(os.path.join(asset_folder, 'gold', str(model_name)), save_best_only=True, mode='auto', verbose=verbose)\n",
    "es = EarlyStopping(monitor='val_loss', patience=patience, mode='auto', verbose=verbose)\n",
    "model.compile(optimizer=Adam(learning_rate), loss=mean_absolute_error, metrics=['mae'])\n",
    "history = model.fit(X_train_scaled, y_train_scaled, validation_data=(X_valid_scaled, y_valid_scaled), epochs=epochs, batch_size=batch_size, callbacks=[es,cp], verbose=verbose) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization of ML-metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Get the number of epochs\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Get the index of the best model\n",
    "best_model_index = np.argmin(val_loss)\n",
    "\n",
    "# Plot the training loss vs validation loss\n",
    "plt.plot(epochs, train_loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.scatter(best_model_index + 1, val_loss[best_model_index], color='g', label='Best Model')\n",
    "plt.title('Training Loss vs Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Display the MAE value of the best model\n",
    "best_model_mae = val_loss[best_model_index]\n",
    "plt.annotate(f'MAE: {best_model_mae:.4f}', (best_model_index + 1, best_model_mae), xytext=(10, 10),\n",
    "             textcoords='offset points', color='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = os.path.join(asset_folder, 'gold', model_name)\n",
    "model = load_model(model_file_path)\n",
    "plot_predictions(model, X_test_scaled, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
